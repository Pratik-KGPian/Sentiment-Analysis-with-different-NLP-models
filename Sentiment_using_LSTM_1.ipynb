{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bd14e3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/pratik/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM,Dense,Dropout\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set()   #important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "38d8ec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"/Users/pratik/Desktop/Sentiment_Analysis/Sentiment-Analysis-with-different-NLP-models/IMDB.csv\")\n",
    "  #reading csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "284aced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection=[]\n",
    "for sentence in data['review']:\n",
    "    words=[word.lower() for word in word_tokenize(sentence)]\n",
    "    collection.append(words)\n",
    "\n",
    "num_words=len(collection)    #tokenization of words and storing them in collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bf042535",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=int(data.shape[0]* 0.8)\n",
    "X_train= data.review[:train_size]\n",
    "Y_train= data.sentiment[:train_size]\n",
    "\n",
    "X_test= data.review[train_size:]\n",
    "Y_test= data.sentiment[train_size:]  #splitting into the train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "94ef5d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize=Tokenizer(num_words)\n",
    "tokenize.fit_on_texts(X_train)\n",
    "X_train=tokenize.texts_to_sequences(X_train)\n",
    "X_train=pad_sequences(X_train,maxlen=128,truncating='post',padding='post')  \n",
    "X_test= tokenize.texts_to_sequences(X_test)\n",
    "X_test=pad_sequences(X_test,maxlen=128,truncating='post',padding='post') #tokenizer model for adding index to each word and setting\n",
    "  #up the fixed length by doing padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "774e8f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   27,     4,     1,    80,  2102,    45,  1073,    12,   100,\n",
       "          147,    39,   316,  2968,   409,   459,    26,  3173,    33,\n",
       "           23,   200,    14,    11,     6,   614,    48,   606,    16,\n",
       "           68,     7,     7,     1,    87,   148,    12,  3256,    68,\n",
       "           41,  2968,    13,    92,  5626,     2, 16202,   134,     4,\n",
       "          569,    60,   271,     8,   200,    36,     1,   673,   139,\n",
       "         1712,    68,    11,     6,    21,     3,   118,    15,     1,\n",
       "         7870,  2257,    38, 11540,    11,   118,  2495,    54,  5662,\n",
       "           16,  5182,     5,  1438,   377,    38,   569,    92,     6,\n",
       "         3730,     8,     1,   360,   353,     4,     1,   673,     7,\n",
       "            7,     9,     6,   431,  2968,    14,    12,     6,     1,\n",
       "        11736,   356,     5,     1, 14689,  6526,  2594,  1087,     9,\n",
       "         2661,  1432,    20, 22583,   534,    32,  4795,  2451,     4,\n",
       "            1,  1193,   117,    29,     1,  6893,    25,  2874, 12191,\n",
       "            2,   392], dtype=int32),\n",
       " 128)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0],len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcbfa9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=LabelEncoder()     # used for labelling with numerical values\n",
    "Y_train= encoder.fit_transform(Y_train)\n",
    "Y_test = encoder.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14653bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()    #sequential model for lstm based model generation\n",
    "model.add(Embedding(input_dim =num_words,output_dim=100,input_length=128,trainable=True))\n",
    "model.add(LSTM(100,dropout=0.1,return_sequences=True))\n",
    "model.add(LSTM(100,dropout=0.1))\n",
    "model.add(Dense(1,activation='sigmoid'))  #giving output between 0 and 1\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d87f2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 128, 100)          5000000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128, 100)          80400     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,160,901\n",
      "Trainable params: 5,160,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()      #summary to watchout the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fbefabda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 22:29:10.850502: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 114s 180ms/step - loss: 0.4595 - accuracy: 0.7837 - val_loss: 0.3587 - val_accuracy: 0.8472\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 112s 179ms/step - loss: 0.2608 - accuracy: 0.9024 - val_loss: 0.3327 - val_accuracy: 0.8582\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 105s 169ms/step - loss: 0.1604 - accuracy: 0.9442 - val_loss: 0.4307 - val_accuracy: 0.8547\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 105s 168ms/step - loss: 0.1050 - accuracy: 0.9649 - val_loss: 0.4330 - val_accuracy: 0.8437\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 106s 170ms/step - loss: 0.0799 - accuracy: 0.9748 - val_loss: 0.5322 - val_accuracy: 0.8454\n"
     ]
    }
   ],
   "source": [
    "returned=model.fit(X_train,Y_train,epochs=5,batch_size=64,validation_data=(X_test,Y_test))  #giving me the history of accuracy\n",
    "#fter every epoch what will be the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9430df73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "Probablity of Positive= [[0.01785491]]\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "#base model for some real-life review example \n",
    "\n",
    "input_sentence=['The movie is worst']\n",
    "input_sentence_tokenized=tokenize.texts_to_sequences(input_sentence)\n",
    "input_sentence_padded=pad_sequences(input_sentence_tokenized,maxlen=128,truncating='post',padding='post')\n",
    "\n",
    "result=model.predict(input_sentence_padded)\n",
    "if(result<0.75):\n",
    "    print(\"Probablity of Positive=\",result)\n",
    "    print(\"Negative\")\n",
    "else:\n",
    "    print(\"Probablity of Positive=\",result)\n",
    "    print(\"Positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d80a0f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "Probablity of Positive= [[0.99823385]]\n",
      "Positive\n"
     ]
    }
   ],
   "source": [
    "input_sentence=['The movie is amazing']\n",
    "input_sentence_tokenized=tokenize.texts_to_sequences(input_sentence)\n",
    "input_sentence_padded=pad_sequences(input_sentence_tokenized,maxlen=128,truncating='post',padding='post')\n",
    "\n",
    "result=model.predict(input_sentence_padded)\n",
    "if(result<0.75):\n",
    "    print(\"Probablity of Positive=\",result)\n",
    "    print(\"Negative\")\n",
    "else:\n",
    "    print(\"Probablity of Positive=\",result)\n",
    "    print(\"Positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3db08c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
